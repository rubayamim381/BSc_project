{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"A82Z8a52E2AF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641291906992,"user_tz":-360,"elapsed":16317,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}},"outputId":"847ca29d-50f5-4368-f07a-5d509f86520b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":24,"metadata":{"id":"hSBDUEUbeK7w","executionInfo":{"status":"ok","timestamp":1641291906999,"user_tz":-360,"elapsed":58,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}}},"outputs":[],"source":["from __future__ import division\n","import os\n","import re\n","import sys\n","import random\n","import time\n","import binascii\n","from bisect import bisect_right\n","from heapq import heappop, heappush\n","import pandas as pd\n","import numpy as np\n","from tabulate import tabulate\n","from itertools import combinations\n","#from beautifultable import BeautifulTable"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"mR-r6rOmeK71","executionInfo":{"status":"ok","timestamp":1641291907007,"user_tz":-360,"elapsed":61,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}}},"outputs":[],"source":["# This is the number of components in the resulting MinHash signatures.\n","numHashes = 100\n","\n","\n","# It ships with data set sizes 100, 1000, 2500, and 10000.\n","numDocs = 100\n","trainFile = \"/content/drive/MyDrive/Colab Notebooks/data/articles_\" + str(numDocs) + \".train.txt\"\n","testFile = \"/content/drive/MyDrive/Colab Notebooks/data/articles_\" + str(numDocs) + \".test.txt\"\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/data/file3.txt', 'w', encoding=\"utf-8\") as dataFile:\n","  \n","    # Iterate through list\n","    for names in [trainFile, testFile]:\n","  \n","        # Open each file in read mode\n","        with open(names, encoding=\"utf-8\") as infile:\n","  \n","            # read the data from file1 and file2 and write it in file3\n","            dataFile.write(infile.read())\n","        dataFile.write(\"\\n\")\n","\n","\n","#truthFile = \"./data/articles_\" + str(numDocs) + \".truth.txt\""]},{"cell_type":"code","execution_count":26,"metadata":{"id":"v66doe8eeK74","executionInfo":{"status":"ok","timestamp":1641291907013,"user_tz":-360,"elapsed":56,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}}},"outputs":[],"source":["#Parse The Ground Truth Tables\n","\n","# Build a dictionary mapping the document IDs to their plagiaries, and vice-versa.\n","#plagiaries = {}\n","\n","# Open the truth file.\n","#f = open(truthFile, \"r\")\n","\n","#for line in f:\n","\n"," # if line[-1] == '\\n':\n","  #    line = line[0:-1]\n","      \n","  #docs = line.split(\" \")\n","\n","  # Map the two documents to each other.\n","  #plagiaries[docs[0]] = docs[1]\n","  #plagiaries[docs[1]] = docs[0]"]},{"cell_type":"code","execution_count":27,"metadata":{"scrolled":true,"id":"-MG80rn9eK76","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641291907014,"user_tz":-360,"elapsed":55,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}},"outputId":"2b793718-44d6-4254-daac-58175afadeae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shingling articles are listed below :- \n","\n","Shingling 100 docs took 0.03 sec.\n","\n","Average shingles per doc: 243.69\n"]}],"source":["#Convert Documents To Sets of Shingles\n","\n","print (\"Shingling articles are listed below :- \")\n","\n","# The current shingle ID value to assign to the next new shingle we encounter.\n","curShingleID = 0\n","\n","# Create a dictionary of the articles, mapping the article identifier (e.g.,\"t8470\") to the list \n","#of shingle IDs that appear in the document.\n","docsAsShingleSets = {};\n","  \n","\n","f = open('/content/drive/MyDrive/Colab Notebooks/data/file3.txt', \"r\" , encoding=\"utf8\")\n","\n","docNames = []\n","\n","t0 = time.time()\n","\n","totalShingles = 0\n","\n","docNM = []\n","\n","for i in range(0, numDocs):\n","  \n","  words = f.readline().split(\" \")  \n","  \n","  docID = words[0]\n","  \n","  # Maintain a list of all document IDs.  \n","  docNames.append(docID)\n","    \n","  del words[0]  \n","  \n","  shinglesInDoc = set()\n","  \n","  # For each word in the document...\n","  for index in range(0, len(words) - 2):\n","\n","    #shingle = list(words[index].union(words[index + 1]).union(words[index + 2]))\n","    shingle = words[index] + \" \" + words[index + 1] + \" \" + words[index + 2]\n","    #print(shingle)\n","    #print(\"\\n\")\n","    \n","\n","    # Hash the shingle to a 32-bit integer.\n","    crc = binascii.crc32(shingle.encode('utf8')) & 0xffffffff\n","    \n","    # Add the hash value to the list of shingles for the current document.  \n","    shinglesInDoc.add(crc)\n","  \n","  docsAsShingleSets[docID] = shinglesInDoc\n","  #print (shinglesInDoc)\n","  #print(\"\\n\")\n","  \n","  # Count the number of shingles across all documents.\n","  totalShingles = totalShingles + (len(words) - 2)\n","\n","f.close()  \n","\n","\n","\n","# Report how long shingling took.\n","print (\"\\nShingling \" + str(numDocs) + \" docs took %.2f sec.\" % (time.time() - t0))\n"," \n","print ('\\nAverage shingles per doc: %.2f' % (totalShingles / numDocs))"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"FrndVii3eK79","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641291907016,"user_tz":-360,"elapsed":54,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}},"outputId":"0263325d-a512-455d-c8df-b2bf42b44625"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Calculating Jaccard Similarities...\n","  (0 / 100)\n","\n","Calculating all Jaccard Similarities took 0.14sec\n"]}],"source":["# =============================================================================\n","#                     Define Triangle Matrices\n","# =============================================================================\n","\n","# Calculate the number of elements needed in our triangle matrix\n","numElems = int(numDocs * (numDocs - 1) / 2)\n","\n","# Initialize two empty lists to store the similarity values\n","#for the actual Jaccard Similarity values\n","JSim = [0 for x in range(numElems)]\n","#for the estimated Jaccard Similarities found by comparing the MinHash signatures.\n","estJSim = [0 for x in range(numElems)]\n","\n","\n","\n","# Define a function to map a 2D matrix coordinate into a 1D index.\n","def getTriangleIndex(i, j):\n","  # If i == j that's an error.\n","  if i == j:\n","    sys.stderr.write(\"Can't access triangle matrix with i == j\")\n","    sys.exit(1)\n","  # If j < i just swap the values.\n","  if j < i:\n","    temp = i\n","    i = j\n","    j = temp\n","  \n","  # Calculate the index within the triangular array.\n","  # This fancy indexing scheme is taken from pg. 211 of:\n","  # http://infolab.stanford.edu/~ullman/mmds/ch6.pdf\n","  # But I adapted it for a 0-based index.\n","  # Note: The division by two should not truncate, it\n","  #       needs to be a float. \n","  k = int(i * (numDocs - (i + 1) / 2.0) + j - i) - 1\n","  \n","  return k\n","\n","\n","# =============================================================================\n","#                 Calculate Jaccard Similarities\n","# =============================================================================\n","# This is included here to show how much slower it is than\n","# the MinHash approach.\n","\n","# Calculating the Jaccard similarities gets really slow for large numbers\n","# of documents.\n","\n","if numDocs <= 2500:\n","    print (\"\\nCalculating Jaccard Similarities...\")\n","    t0 = time.time()\n","\n","    # For every document pair...\n","    for i in range(0, numDocs):\n","      \n","      # Print progress every 100 documents.\n","      if (i % 100) == 0:\n","        print (\"  (\" + str(i) + \" / \" + str(numDocs) + \")\")\n","\n","      # Retrieve the set of shingles for document i.\n","      s1 = docsAsShingleSets[docNames[i]] #docNames = ID from data\n","      \n","      for j in range(i + 1, numDocs):\n","        # Retrieve the set of shingles for document j.\n","        s2 = docsAsShingleSets[docNames[j]]\n","        \n","        # Calculate and store the actual Jaccard similarity.\n","        JSim[getTriangleIndex(i, j)] = (len(s1.intersection(s2)) / len(s1.union(s2)))\n","        # Retrieve the estimated similarity value for this pair.\n","\n","    a = np.array([JSim])\n","\n","    # Calculate the elapsed time (in seconds)\n","    elapsed = (time.time() - t0)\n","    print (\"\\nCalculating all Jaccard Similarities took %.2fsec\" % elapsed)\n","\n","# Delete the Jaccard Similarities, since it's a pretty big matrix.    \n","del JSim\n","#np.prod(a.shape)"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"L6Cc96HPeK7_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641292611567,"user_tz":-360,"elapsed":6871,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}},"outputId":"f3791c3e-0401-4f47-b121-ec7e264b2da7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Generating random hash functions...\n","\n","Generating MinHash signatures for all documents...\n","\n","Generating MinHash signatures took 1.33sec\n"]}],"source":["# =============================================================================\n","#                 Generate MinHash Signatures\n","# =============================================================================\n","\n","# Time this step.\n","t0 = time.time()\n","\n","print (\"\\nGenerating random hash functions...\")\n","\n","# Record the maximum shingle ID that we assigned.\n","maxShingleID = 2**32-1\n","\n","# We need the next largest prime number above 'maxShingleID'.\n","# I looked this value up here: \n","# http://compoasso.free.fr/primelistweb/page/prime/liste_online_en.php\n","nextPrime = 4294967311\n","\n","\n","# Our random hash function will take the form of:\n","#   h(x) = (a*x + b) % c\n","# Where 'x' is the input value, \n","#'a' and 'b' are random coefficients, \n","#and 'c' is a prime number just greater than maxShingleID.\n","\n","# Generate a list of 'k' random coefficients for the random hash functions\n","def pickRandomCoeffs(k):\n","  # Create a list of 'k' random values.\n","  randList = []\n","  \n","  while k > 0:\n","    # Get a random shingle ID.\n","    randIndex = random.randint(0, maxShingleID) \n","  \n","    # Ensure that each random number is unique.\n","    while randIndex in randList:\n","      randIndex = random.randint(0, maxShingleID) \n","    \n","    # Add the random number to the list.\n","    randList.append(randIndex)\n","    k = k - 1\n","    \n","  return randList\n","\n","# For each of the 'numHashes' hash functions, generate a different coefficient 'a' and 'b'.   \n","coeffA = pickRandomCoeffs(numHashes)\n","coeffB = pickRandomCoeffs(numHashes)\n","\n","print (\"\\nGenerating MinHash signatures for all documents...\")\n","\n","# List of documents represented as signature vectors\n","signatures = []\n","\n","# For each document...\n","for docID in docNames:\n","  \n"," \n","  shingleIDSet = docsAsShingleSets[docID]\n","  \n","\n","  signature = []\n","  \n","  # For each of the random hash functions...\n","  for i in range(0, numHashes):\n","    \n","    # For each of the shingles actually in the document, calculate its hash code using hash function 'i'. \n","    minHashCode = nextPrime + 1\n","    \n","    # For each shingle in the document...\n","    for shingleID in shingleIDSet:\n","      # Evaluate the hash function.\n","      hashCode = (coeffA[i] * shingleID + coeffB[i]) % nextPrime \n","      \n","      # Track the lowest hash code seen.\n","      if hashCode < minHashCode:\n","        minHashCode = hashCode\n","\n","    # Add the smallest hash code value as component number 'i' of the signature.\n","    signature.append(minHashCode)\n","    # Calculate the elapsed time (in seconds)\n","  #print(signature)\n","  \n","  # Store the MinHash signature for this document.\n","  signatures.append(signature)\n","\n","# Calculate the elapsed time (in seconds)\n","elapsed = (time.time() - t0)\n","        \n","print (\"\\nGenerating MinHash signatures took %.2fsec\" % elapsed)  "]},{"cell_type":"code","execution_count":40,"metadata":{"id":"XE-8hxQLeK8A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641292688807,"user_tz":-360,"elapsed":848,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}},"outputId":"c9359911-235d-4551-f750-95903d69ae3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Comparing all signatures...\n","\n","Comparing MinHash signatures for  100  number of permutations took 0.13sec\n","\n","\n","\t...Comparing all signatures...\n","\n","List of Document Pairs with J(d1,d2) more than  0.8 is considered as a similarity\n","\n","╒═════════╤═════════╤═══════════════╤════════════╤═════════════╕\n","│ Doc_1   │ Doc_2   │   Estimated J │   Actual J │    Distance │\n","╞═════════╪═════════╪═══════════════╪════════════╪═════════════╡\n","│ t980    │ t2023   │          0.97 │   0.979167 │ 0.00916667  │\n","├─────────┼─────────┼───────────────┼────────────┼─────────────┤\n","│ t9536   │ t9537   │          0.98 │   0.975    │ 0.005       │\n","├─────────┼─────────┼───────────────┼────────────┼─────────────┤\n","│ t1088   │ t5015   │          0.99 │   0.980545 │ 0.00945525  │\n","├─────────┼─────────┼───────────────┼────────────┼─────────────┤\n","│ t1297   │ t4638   │          0.98 │   0.98062  │ 0.000620155 │\n","├─────────┼─────────┼───────────────┼────────────┼─────────────┤\n","│ t1768   │ t5248   │          0.99 │   0.980315 │ 0.00968504  │\n","├─────────┼─────────┼───────────────┼────────────┼─────────────┤\n","│ t1952   │ t3495   │          0.99 │   0.978448 │ 0.0115517   │\n","╘═════════╧═════════╧═══════════════╧════════════╧═════════════╛\n","\n","Whole process took 0.28 seconds\n"]}],"source":["# =============================================================================\n","#                     Compare All Signatures\n","# =============================================================================  \n","\n","print (\"\\nComparing all signatures...\")  \n","  \n","# N x N matrix\n","\n","\n","t0 = time.time()\n","\n","# For each of the test documents...\n","for i in range(0, numDocs):\n","  # Get the MinHash signature for document i.\n","  signature1 = signatures[i]\n","    \n","  # For each of the other test documents...\n","  for j in range(i + 1, numDocs):\n","    \n","    # Get the MinHash signature for document j.\n","    signature2 = signatures[j]\n","    \n","    count = 0\n","    # Count the number of positions in the minhash signature which are equal.\n","    for k in range(0, numHashes):\n","      count = count + (signature1[k] == signature2[k])\n","    \n","    # Record the percentage of positions which matched.    \n","    estJSim[getTriangleIndex(i, j)] = (count / numHashes)\n","\n","# Calculate the elapsed time (in seconds)\n","elapsed = (time.time() - t0)\n","        \n","print (\"\\nComparing MinHash signatures for \", numHashes, \" number of permutations took %.2fsec\" % elapsed  )\n","\n","# =============================================================================\n","#                     Compare All Signatures\n","# =============================================================================  \n","\n","print (\"\\n\\n\\t...Comparing all signatures...\")  \n","  \n","# N x N matrix\n","#t0 = time.time()\n","\n","# For each of the test documents...\n","for i in range(0, numDocs):\n","  # Get the MinHash signature for document i.\n","  signature1 = signatures[i]\n","    \n","  # For each of the other test documents...\n","  for j in range(i + 1, numDocs):\n","    \n","    # Get the MinHash signature for document j.\n","    signature2 = signatures[j]\n","    \n","    count = 0\n","    # Count the number of positions in the minhash signature which are equal.\n","    for k in range(0, numHashes):\n","      count = count + (signature1[k] == signature2[k])\n","    \n","    # Record the percentage of positions which matched.    \n","    estJSim[getTriangleIndex(i, j)] = (count / numHashes)\n","\n","\n","    \n","    \n","# =============================================================================\n","#                   Display Similar Document Pairs\n","# =============================================================================  \n","\n","# Count the true positives and false positives.\n","data = []\n","tp = 0\n","fp = 0\n","\n","col_names = [\"Doc_1\", \"Doc_2\",\"Estimated J\",\"Actual J\",\"Distance\"]\n","  \n","threshold = 0.8  \n","print (\"\\nList of Document Pairs with J(d1,d2) more than \", threshold, \"is considered as a similarity\\n\")\n","\n","#print (\"                   Est. J   Act. J\")\n","\n","\n","# For each of the document pairs...\n","for i in range(0, numDocs):  \n","  for j in range(i + 1, numDocs):\n","    # Retrieve the estimated similarity value for this pair.\n","    estJ = estJSim[getTriangleIndex(i, j)]\n","    \n","    \n","    if estJ > threshold:\n","    \n","      # Calculate the actual Jaccard similarity for validation.\n","      s1 = docsAsShingleSets[docNames[i]]\n","      s2 = docsAsShingleSets[docNames[j]]\n","      J = (len(s1.intersection(s2)) / len(s1.union(s2)))\n","      distance = abs(float(estJ - J))\n","      \n","      data += [[docNames[i], docNames[j], estJ,  J, distance]]\n","\n","print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))\n","\n","# Calculate the elapsed time (in seconds)\n","elapsed2 = (time.time() - t0)\n","print(\"\\nWhole process took %.2f seconds\" % elapsed2)\n","\n","#table.append_row([docNames[i],  docNames[j],  estJ,  J])\n","#print(table)\n","#display table\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"2Sw07s6SeK8C","executionInfo":{"status":"ok","timestamp":1641292734369,"user_tz":-360,"elapsed":549,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}}},"outputs":[],"source":["#Here is the algorithm:\n","\n","    #1. Divide the signature matrix into b bands, each band having r rows.\n","    #2. For each band, hash its portion of each column to a hash table with k buckets.\n","    #3. Candidate column pairs are those that hash to the same bucket for at least 1 band.\n","    #4. Tune b and r to catch most similar pairs but few non similar pairs.\n","\n","# =============================================================================\n","#                  Using LSH display the candidate pairs\n","# =============================================================================  \n","\n","class LSH:\n","    t0 = time.time()\n","    buckets = []\n","    counter = 0\n","    def __init__(self, b):\n","        self.b = b\n","        for i in range(b):\n","            self.buckets.append({})\n","\n","    def create_subvecs(self, signature):\n","        l = len(signature)\n","        assert l % self.b == 0, 'Error! Number of hashes should be divisible by buckets'\n","        r = int(l / self.b) #we will get row from this line \n","        # break signature into subvectors\n","        subvecs = []\n","        for i in range(0, l, r):\n","            subvecs.append(signature[i:i+r])\n","        return np.stack(subvecs)\n","\n","    def add_hash(self, signature):\n","        subvecs = self.create_subvecs(signature).astype(str)\n","        for i, subvec in enumerate(subvecs):\n","            subvec = ', '.join(subvec)\n","            if subvec not in self.buckets[i].keys():\n","                self.buckets[i][subvec] = []\n","            self.buckets[i][subvec].append(self.counter+1)\n","        self.counter += 1\n","\n","    def check_candidates(self):\n","        \n","        candidates = []\n","        for bucket_band in self.buckets:\n","            keys = bucket_band.keys()\n","            for bucket in keys:\n","                hits = bucket_band[bucket]\n","                if len(hits) > 1:\n","                    candidates.extend(combinations(hits, 2))\n","        return set(candidates)\n","\n","\n","b = 25\n","lsh = LSH(b)"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"4tSOxVGFeK8D","executionInfo":{"status":"ok","timestamp":1641292738096,"user_tz":-360,"elapsed":667,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}}},"outputs":[],"source":["for signature in signatures:\n","  lsh.add_hash(signature)\n","#lsh.buckets"]},{"cell_type":"code","source":["candidate_pairs = lsh.check_candidates()\n","# Calculate the elapsed time (in seconds)\n","elapsed = (time.time() - t0)\n","print (\"Generating Candidate pairs took %.2fsec\" % elapsed) \n","print(\"The length of candidate pair is: \", len(candidate_pairs))\n","c = list(candidate_pairs)"],"metadata":{"id":"pK8r_-Ldjlwg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641292749247,"user_tz":-360,"elapsed":693,"user":{"displayName":"Rubaya Akter Mim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghv7Q5aMTaQ6Dp7vI4cEieVFqcP2X_tI4xMNkEnKQ=s64","userId":"14574301021038508617"}},"outputId":"4743545c-0df5-49fd-e873-7e2378362842"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating Candidate pairs took 60.53sec\n","The length of candidate pair is:  6\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"ZDNCEAOAq9Qb"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"LSH_Project.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}